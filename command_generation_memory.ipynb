{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from collections import namedtuple\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "# a snapshot of state to be stored in replay memory\n",
        "Transition = namedtuple('Transition', ('observation_list', 'quest_list', 'possible_words', 'word_indices', 'reward', 'is_final'))\n",
        "\n",
        "\n",
        "class PrioritizedReplayMemory(object):\n",
        "\n",
        "    def __init__(self, capacity=100000, priority_fraction=0.0, discount_gamma=1.0):\n",
        "        # prioritized replay memory\n",
        "        self.priority_fraction = priority_fraction\n",
        "        self.discount_gamma = discount_gamma\n",
        "        self.alpha_capacity = int(capacity * priority_fraction)\n",
        "        self.beta_capacity = capacity - self.alpha_capacity\n",
        "        self.alpha_memory, self.beta_memory = [], []\n",
        "        self.alpha_position, self.beta_position = 0, 0\n",
        "\n",
        "    def push(self, is_prior=False, *args):\n",
        "        \"\"\"Saves a transition.\"\"\"\n",
        "        if self.priority_fraction == 0.0:\n",
        "            is_prior = False\n",
        "        if is_prior:\n",
        "            if len(self.alpha_memory) < self.alpha_capacity:\n",
        "                self.alpha_memory.append(None)\n",
        "            self.alpha_memory[self.alpha_position] = Transition(*args)\n",
        "            self.alpha_position = (self.alpha_position + 1) % self.alpha_capacity\n",
        "        else:\n",
        "            if len(self.beta_memory) < self.beta_capacity:\n",
        "                self.beta_memory.append(None)\n",
        "            self.beta_memory[self.beta_position] = Transition(*args)\n",
        "            self.beta_position = (self.beta_position + 1) % self.beta_capacity\n",
        "\n",
        "    def get_next_final_pos(self, which_memory, head):\n",
        "        i = head\n",
        "        while True:\n",
        "            if i >= len(which_memory):\n",
        "                return None\n",
        "            if which_memory[i].is_final:\n",
        "                return i\n",
        "            i += 1\n",
        "        return None\n",
        "\n",
        "    def _get_single_transition(self, n, which_memory):\n",
        "        assert n > 0\n",
        "        tried_times = 0\n",
        "        while True:\n",
        "            tried_times += 1\n",
        "            if tried_times >= 50:\n",
        "                return None\n",
        "            if len(which_memory) <= n:\n",
        "                return None\n",
        "\n",
        "            head = np.random.randint(0, len(which_memory) - n)\n",
        "            # if n is 1, then head can't be is_final\n",
        "            if n == 1:\n",
        "                if which_memory[head].is_final:\n",
        "                    continue\n",
        "            #  if n > 1, then all except tail can't be is_final\n",
        "            else:\n",
        "                if np.any([item.is_final for item in which_memory[head: head + n]]):\n",
        "                    continue\n",
        "\n",
        "            next_final = self.get_next_final_pos(which_memory, head)\n",
        "            if next_final is None:\n",
        "                continue\n",
        "\n",
        "            # all good\n",
        "            obs = which_memory[head].observation_list\n",
        "            quest = which_memory[head].quest_list\n",
        "            possible_words = which_memory[head].possible_words\n",
        "            word_indices = which_memory[head].word_indices\n",
        "            \n",
        "            next_obs = which_memory[head + n].observation_list\n",
        "            next_possible_words = which_memory[head + n].possible_words\n",
        "\n",
        "            rewards_up_to_next_final = [self.discount_gamma ** i * which_memory[head + i].reward for i in range(next_final - head + 1)]\n",
        "            reward = torch.sum(torch.stack(rewards_up_to_next_final))\n",
        "\n",
        "            return (obs, quest, possible_words, word_indices, reward, next_obs, next_possible_words, n)\n",
        "\n",
        "    def _get_batch(self, n_list, which_memory):\n",
        "        res = []\n",
        "        for i in range(len(n_list)):\n",
        "            output = self._get_single_transition(n_list[i], which_memory)\n",
        "            if output is None:\n",
        "                continue\n",
        "            res.append(output)\n",
        "\n",
        "        if len(res) == 0:\n",
        "            return None\n",
        "        return res\n",
        "\n",
        "    def get_batch(self, batch_size, multi_step=1):\n",
        "        from_alpha = min(int(self.priority_fraction * batch_size), len(self.alpha_memory))\n",
        "        from_beta = min(batch_size - from_alpha, len(self.beta_memory))\n",
        "        res = []\n",
        "        if from_alpha == 0:\n",
        "            res_alpha = None\n",
        "        else:\n",
        "            res_alpha = self._get_batch(np.random.randint(1, multi_step + 1, size=from_alpha), self.alpha_memory)\n",
        "        if from_beta == 0:\n",
        "            res_beta = None\n",
        "        else:\n",
        "            res_beta = self._get_batch(np.random.randint(1, multi_step + 1, size=from_beta), self.beta_memory)\n",
        "        if res_alpha is None and res_beta is None:\n",
        "            return None\n",
        "        if res_alpha is not None:\n",
        "            res += res_alpha\n",
        "        if res_beta is not None:\n",
        "            res += res_beta\n",
        "\n",
        "        obs_list, quest_list, possible_words_list, word_indices_list = [], [], [], []\n",
        "        reward_list, next_obs_list, next_possible_words_list, actual_n_list = [], [], [], []\n",
        "\n",
        "        for item in res:\n",
        "            obs, quest, possible_words, word_indices, reward, next_obs, next_possible_words, n = item\n",
        "\n",
        "            obs_list.append(obs)\n",
        "            quest_list.append(quest)\n",
        "            possible_words_list.append(possible_words)\n",
        "            word_indices_list.append(word_indices)\n",
        "            reward_list.append(reward)\n",
        "            next_obs_list.append(next_obs)\n",
        "            next_possible_words_list.append(next_possible_words)\n",
        "            actual_n_list.append(n)\n",
        "\n",
        "        chosen_indices = list(zip(*word_indices_list))\n",
        "        chosen_indices = [torch.stack(item, 0) for item in chosen_indices]  # list of batch x 1\n",
        "        rewards = torch.stack(reward_list, 0)  # batch\n",
        "        actual_n_list = np.array(actual_n_list)\n",
        "\n",
        "        return obs_list, quest_list, possible_words_list, chosen_indices, rewards, next_obs_list, next_possible_words_list, actual_n_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.alpha_memory) + len(self.beta_memory)\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}