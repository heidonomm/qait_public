{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from collections import namedtuple\n",
        "\n",
        "\n",
        "# a snapshot of state to be stored in replay memory\n",
        "qa_Transition = namedtuple('qa_Transition', ('observation_list', 'quest_list', 'answer_strings'))\n",
        "\n",
        "\n",
        "class PrioritizedReplayMemory(object):\n",
        "\n",
        "    def __init__(self, capacity=100000, priority_fraction=0.0):\n",
        "        # prioritized replay memory\n",
        "        self.priority_fraction = priority_fraction\n",
        "        self.alpha_capacity = int(capacity * priority_fraction)\n",
        "        self.beta_capacity = capacity - self.alpha_capacity\n",
        "        self.alpha_memory, self.beta_memory = [], []\n",
        "        self.alpha_position, self.beta_position = 0, 0\n",
        "        self.alpha_rewards, self.beta_rewards = [], []\n",
        "\n",
        "    def push(self, is_prior=False, reward=0.0, *args):\n",
        "        \"\"\"Saves a transition.\"\"\"\n",
        "        if self.priority_fraction == 0.0:\n",
        "            is_prior = False\n",
        "        if is_prior:\n",
        "            if len(self.alpha_memory) < self.alpha_capacity:\n",
        "                self.alpha_memory.append(None)\n",
        "            self.alpha_memory[self.alpha_position] = qa_Transition(*args)\n",
        "            self.alpha_position = (self.alpha_position + 1) % self.alpha_capacity\n",
        "            self.alpha_rewards.append(reward)\n",
        "            if len(self.alpha_rewards) > self.alpha_capacity:\n",
        "                self.alpha_rewards = self.alpha_rewards[1:]\n",
        "        else:\n",
        "            if len(self.beta_memory) < self.beta_capacity:\n",
        "                self.beta_memory.append(None)\n",
        "            self.beta_memory[self.beta_position] = qa_Transition(*args)\n",
        "            self.beta_position = (self.beta_position + 1) % self.beta_capacity\n",
        "            self.beta_rewards.append(reward)\n",
        "            if len(self.beta_rewards) > self.beta_capacity:\n",
        "                self.beta_rewards = self.beta_rewards[1:]\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        if self.priority_fraction == 0.0:\n",
        "            from_beta = min(batch_size, len(self.beta_memory))\n",
        "            res = random.sample(self.beta_memory, from_beta)\n",
        "        else:\n",
        "            from_alpha = min(int(self.priority_fraction * batch_size), len(self.alpha_memory))\n",
        "            from_beta = min(batch_size - int(self.priority_fraction * batch_size), len(self.beta_memory))\n",
        "            res = random.sample(self.alpha_memory, from_alpha) + random.sample(self.beta_memory, from_beta)\n",
        "        return res\n",
        "\n",
        "    def avg_rewards(self):\n",
        "        if len(self.alpha_rewards) == 0 and len(self.beta_rewards) == 0 :\n",
        "            return 0.0\n",
        "        return np.mean(self.alpha_rewards + self.beta_rewards)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.alpha_memory) + len(self.beta_memory)\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}